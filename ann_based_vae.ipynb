{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16016,"status":"ok","timestamp":1718559263264,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"},"user_tz":-60},"id":"asV86I9iyIHX","outputId":"e0213ff0-85b3-487f-a0fe-2c9da31797ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"PAGpnDCJdldq"},"source":["Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10250,"status":"ok","timestamp":1718559273513,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"},"user_tz":-60},"id":"-alScVnKPlQy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import math\n","import random\n","import os\n","import os.path\n","import numpy as np\n","import logging\n","import argparse\n","from argparse import ZERO_OR_MORE\n","from torch.nn.modules.module import T\n","from torch.utils.tensorboard import SummaryWriter as writer\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from skimage.metrics import structural_similarity as ssim\n","import time"]},{"cell_type":"markdown","metadata":{"id":"HoALbmmpLVrH"},"source":["Parameters"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":779,"status":"ok","timestamp":1718559274285,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"},"user_tz":-60},"id":"pFd89-kEK5WU"},"outputs":[],"source":["epochs = 150\n","batch_size = 32 # reduced from 250 to 32\n","# n_steps = 16 # timestep\n","in_channels = 1\n","lr = 0.001 # changed from 0.001 to 0.0001\n","# n_class = 10\n","latent_dim = 35 # changed from 128 to 25 (continue with 25)\n","input_size = 40\n","k = 20 # multiplier of channel\n","# scheduled = True # whether to apply scheduled sampling\n","# checkpoint_filename = 'vae_checkpoint_32_16_250_full_dim25.pth'\n","save_folder = '/content/drive/MyDrive/TU060/Dissertation/Models/V3/VAE/z_dim=30/full'\n","# Check if the directory exists, if not, create it\n","if not os.path.exists(save_folder):\n","    os.makedirs(save_folder)"]},{"cell_type":"markdown","metadata":{"id":"rBzC01iGxqi9"},"source":["Load data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8764,"status":"ok","timestamp":1718559283047,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"},"user_tz":-60},"id":"mGEAEDZPxpoy"},"outputs":[],"source":["# Load data\n","raw = np.load('/content/drive/MyDrive/TU060/Dissertation/Dataset/sampled_maps_10000_01.npy')\n","# raw = np.load('/content/drive/MyDrive/TU060/Dissertation/Dataset/sampled_maps_20000_01.npy')\n","# raw = np.load('/content/drive/MyDrive/TU060/Dissertation/Dataset/sampled_maps_40000_01.npy')\n","# raw = np.load('/content/drive/MyDrive/TU060/Dissertation/Dataset/sampled_maps_80000_01.npy')\n","# raw = np.load('/content/drive/MyDrive/TU060/Dissertation/Dataset/sampled_maps_160000_01.npy')\n","# raw = np.load('/content/drive/MyDrive/TU060/Dissertation/Dataset/TopoMaps_s01.npy')\n","\n","\n","# Normalise data between -1 and 1\n","# data_norm = (raw - raw.min()) / (raw.max() - raw.min()) * 2 - 1\n","#Normalise the data\n","# data_norm = (raw - raw.min()) / (raw.max() - raw.min())\n","\n","# Initialize normalized data array\n","data_norm = np.zeros_like(raw)\n","\n","# Normalize each image individually\n","for i in range(len(raw)):\n","    min_val = raw[i].min()\n","    max_val = raw[i].max()\n","    data_norm[i] = (raw[i] - min_val) / (max_val - min_val)\n","\n","# Reshape data to have a single channel\n","data_norm_reshape = data_norm.reshape(-1, 1, raw.shape[1], raw.shape[2]).astype(np.float32)\n","\n","\n","# Split data into training, validation, and testing\n","data_train, data_test = train_test_split(data_norm_reshape, test_size=0.3, random_state=42, shuffle=True)\n","data_test, data_val = train_test_split(data_test, test_size=0.5, random_state=42, shuffle=True)\n","\n","train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"_3-ElNQxTXzx"},"source":["# ANN-VAE"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718559283047,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"},"user_tz":-60},"id":"FVN6iTlFP3Nc"},"outputs":[],"source":["class VanillaVAE(nn.Module):\n","    def __init__(self, in_channels, latent_dim) -> None:\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.latent_dim = latent_dim\n","\n","        modules = []\n","        hidden_dims = [32, 64, 128]\n","        self.hidden_dims = hidden_dims.copy()\n","\n","        # Build Encoder\n","        for h_dim in hidden_dims:\n","            modules.append(\n","                nn.Sequential(\n","                    nn.Conv2d(in_channels, out_channels=h_dim,\n","                              kernel_size= 3, stride= 2, padding  = 1),\n","                    nn.BatchNorm2d(h_dim),\n","                    nn.LeakyReLU())\n","            )\n","            in_channels = h_dim\n","\n","        self.encoder = nn.Sequential(*modules)\n","        self.fc_mu = nn.Linear(hidden_dims[-1]*25, latent_dim) # changed from 4 to 25\n","        self.fc_var = nn.Linear(hidden_dims[-1]*25, latent_dim) # changed from 4 to 25\n","\n","        # # Print the dimensions of fc_mu and fc_var\n","        # print(f\"Dimensions of fc_mu: {self.fc_mu.weight.shape}\")\n","        # print(f\"Dimensions of fc_var: {self.fc_var.weight.shape}\")\n","\n","\n","\n","        # Build Decoder\n","        modules = []\n","\n","        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 25) # changed from 4 to 25\n","\n","        hidden_dims.reverse()\n","\n","        for i in range(len(hidden_dims) - 1):\n","            modules.append(\n","                nn.Sequential(\n","                    nn.ConvTranspose2d(hidden_dims[i],\n","                                       hidden_dims[i + 1],\n","                                       kernel_size=3,\n","                                       stride = 2,\n","                                       padding=1,\n","                                       output_padding=1),\n","                    nn.BatchNorm2d(hidden_dims[i + 1]),\n","                    nn.LeakyReLU())\n","            )\n","\n","        self.decoder = nn.Sequential(*modules)\n","\n","        self.final_layer = nn.Sequential(\n","                            nn.ConvTranspose2d(hidden_dims[-1],\n","                                               hidden_dims[-1],\n","                                               kernel_size=3,\n","                                               stride=2,\n","                                               padding=1,\n","                                               output_padding=1),\n","                            nn.BatchNorm2d(hidden_dims[-1]),\n","                            nn.LeakyReLU(),\n","                            nn.ConvTranspose2d(hidden_dims[-1], out_channels= self.in_channels, # deconvにしてみる\n","                                      kernel_size= 3, padding= 1),\n","                            nn.Sigmoid()) # Changed from nn.Tanh() to nn.Sigmoid()\n","\n","\n","    def encode(self, input):\n","        result = self.encoder(input)\n","        result = torch.flatten(result, start_dim=1)\n","\n","        # Print the size of the intermediate tensor\n","        # print(f\"Size of result tensor in encode method: {result.size()}\")\n","\n","        # Split the result into mu and var components\n","        # of the latent Gaussian distribution\n","        mu = self.fc_mu(result)\n","        log_var = self.fc_var(result)\n","\n","        # Print the sizes of mu and log_var tensors\n","        # print(f\"Size of mu tensor: {mu.size()}\")\n","        # print(f\"Size of log_var tensor: {log_var.size()}\")\n","\n","        return [mu, log_var]\n","\n","    def decode(self, z):\n","        \"\"\"\n","        Maps the given latent codes\n","        onto the image space.\n","        :param z: (Tensor) [B x D]\n","        :return: (Tensor) [B x C x H x W]\n","        \"\"\"\n","\n","        result = self.decoder_input(z)\n","        result = result.view(-1, self.hidden_dims[-1], 5, 5) # changed from 2 to 5\n","\n","        # Print the size of the intermediate tensor\n","        # print(f\"Size of result tensor in decode method: {result.size()}\")\n","\n","        result = self.decoder(result)\n","        result = self.final_layer(result)\n","        return result\n","\n","\n","    def reparameterize(self, mu, logvar):\n","        \"\"\"\n","        Reparameterization trick to sample from N(mu, var) from\n","        N(0,1).\n","        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n","        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n","        :return: (Tensor) [B x D]\n","        \"\"\"\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return eps * std + mu\n","\n","    def forward(self, input):\n","        mu, log_var = self.encode(input)\n","        z = self.reparameterize(mu, log_var)\n","        return  self.decode(z), mu, log_var\n","\n","    def loss_function(self,\n","                      recons_img,\n","                      input_img,\n","                      mu, log_var, kld_weight) -> dict:\n","        \"\"\"\n","        Computes the VAE loss function.\n","        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n","        :param args:\n","        :param kwargs:\n","        :return:\n","        \"\"\"\n","\n","        recons_loss =F.mse_loss(recons_img, input_img)\n","\n","\n","        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n","        loss = recons_loss + kld_weight * kld_loss\n","        \"\"\"\n","        kld_loss = -0.5 * torch.mean(1 + log_var - mu ** 2 - log_var.exp())\n","        loss = recons_loss + kld_loss\n","        \"\"\"\n","        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD':kld_loss}\n","\n","    def sample(self,\n","               num_samples:int,\n","               current_device: int, **kwargs):\n","        \"\"\"\n","        Samples from the latent space and return the corresponding\n","        image space map.\n","        :param num_samples: (Int) Number of samples\n","        :param current_device: (Int) Device to run the model\n","        :return: (Tensor)\n","        \"\"\"\n","        z = torch.randn(num_samples,\n","                        self.latent_dim)\n","\n","        z = z.to(current_device)\n","\n","        samples = self.decode(z)\n","        return samples"]},{"cell_type":"markdown","metadata":{"id":"YbCc-5wuTdoR"},"source":["# Main VAE"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718559283047,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"},"user_tz":-60},"id":"LiEnll05WJ0t"},"outputs":[],"source":["# Define the directory to save the model checkpoints\n","checkpoint_dir = '/content/drive/MyDrive/TU060/Dissertation/Checkpoints/V3'\n","\n","# Check if the checkpoint directory exists, if not, create it\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","\n","# Define a function to save the model checkpoint after every epoch\n","def save_checkpoint(epoch, model, optimizer, loss, filename):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss,\n","    }\n","    torch.save(checkpoint, os.path.join(checkpoint_dir, filename))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lbc2d4tLlWmP","executionInfo":{"status":"ok","timestamp":1718559449457,"user_tz":-60,"elapsed":166412,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"}},"outputId":"b7aed679-f944-4c10-b212-31d53f164863"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/150], Time: 9.12 seconds\n","Epoch [1/150], Train Loss: 0.04465967149393899, Val Loss: 0.06143754307428996\n","Epoch [1/150], Train MSE: 0.036594949662685394, Train MAE: 0.14550326764583588, Train SSIM: 0.3179758627017082\n","Epoch [1/150], Val MSE: 0.031192278489470482, Val MAE: 0.13512784242630005, Val SSIM: 0.4288103322237335\n","Epoch [2/150], Time: 8.62 seconds\n","Epoch [2/150], Train Loss: 0.03520117292233876, Val Loss: 0.06637706057230632\n","Epoch [2/150], Train MSE: 0.028038527816534042, Train MAE: 0.12653112411499023, Train SSIM: 0.45733325781822853\n","Epoch [2/150], Val MSE: 0.02478119172155857, Val MAE: 0.11797056347131729, Val SSIM: 0.5172676851787544\n","Epoch [3/150], Time: 8.80 seconds\n","Epoch [3/150], Train Loss: 0.033728627852031165, Val Loss: 0.06110414771238963\n","Epoch [3/150], Train MSE: 0.02628406509757042, Train MAE: 0.12175945937633514, Train SSIM: 0.5070330187589432\n","Epoch [3/150], Val MSE: 0.02506137080490589, Val MAE: 0.11764025688171387, Val SSIM: 0.5290189527828564\n","Epoch [4/150], Time: 8.47 seconds\n","Epoch [4/150], Train Loss: 0.03302759833846773, Val Loss: 0.06376950162649155\n","Epoch [4/150], Train MSE: 0.02538861334323883, Train MAE: 0.11926101893186569, Train SSIM: 0.529449661282684\n","Epoch [4/150], Val MSE: 0.025806084275245667, Val MAE: 0.12010795623064041, Val SSIM: 0.579082490666365\n","Epoch [5/150], Time: 8.71 seconds\n","Epoch [5/150], Train Loss: 0.03267569720319339, Val Loss: 0.05893064202864965\n","Epoch [5/150], Train MSE: 0.02494240738451481, Train MAE: 0.11796978116035461, Train SSIM: 0.5419504406319641\n","Epoch [5/150], Val MSE: 0.024298930540680885, Val MAE: 0.1157996729016304, Val SSIM: 0.5555177760656992\n","Epoch [6/150], Time: 8.58 seconds\n","Epoch [6/150], Train Loss: 0.032523103203092305, Val Loss: 0.06469123111168544\n","Epoch [6/150], Train MSE: 0.02473563142120838, Train MAE: 0.11738546192646027, Train SSIM: 0.5480399905044211\n","Epoch [6/150], Val MSE: 0.0242913905531168, Val MAE: 0.11593849211931229, Val SSIM: 0.5386020593900245\n","Epoch [7/150], Time: 8.57 seconds\n","Epoch [7/150], Train Loss: 0.032194212934800556, Val Loss: 0.058742890328168866\n","Epoch [7/150], Train MSE: 0.024456987157464027, Train MAE: 0.11646819859743118, Train SSIM: 0.5529731618638217\n","Epoch [7/150], Val MSE: 0.024537554010748863, Val MAE: 0.11716415733098984, Val SSIM: 0.5400530881625888\n","Epoch [8/150], Time: 8.35 seconds\n","Epoch [8/150], Train Loss: 0.032151574867112294, Val Loss: 0.056677873889605206\n","Epoch [8/150], Train MSE: 0.024419503286480904, Train MAE: 0.11630260199308395, Train SSIM: 0.5548790505934751\n","Epoch [8/150], Val MSE: 0.02507122792303562, Val MAE: 0.11754301190376282, Val SSIM: 0.5460429627109706\n","Epoch [9/150], Time: 8.65 seconds\n","Epoch [9/150], Train Loss: 0.03203514006308147, Val Loss: 0.059136119991540906\n","Epoch [9/150], Train MSE: 0.02428441122174263, Train MAE: 0.11588511615991592, Train SSIM: 0.5601955571768891\n","Epoch [9/150], Val MSE: 0.023893974721431732, Val MAE: 0.11463017761707306, Val SSIM: 0.5633653514915589\n","Epoch [10/150], Time: 8.71 seconds\n","Epoch [10/150], Train Loss: 0.03193903081757682, Val Loss: 0.06517391415437063\n","Epoch [10/150], Train MSE: 0.024102652445435524, Train MAE: 0.11541546136140823, Train SSIM: 0.5621773910934104\n","Epoch [10/150], Val MSE: 0.022260522469878197, Val MAE: 0.10990118235349655, Val SSIM: 0.5935684631357947\n","Epoch [11/150], Time: 8.26 seconds\n","Epoch [11/150], Train Loss: 0.03183311007704054, Val Loss: 0.06068496237198512\n","Epoch [11/150], Train MSE: 0.024063484743237495, Train MAE: 0.11510910838842392, Train SSIM: 0.5665035220444193\n","Epoch [11/150], Val MSE: 0.022994929924607277, Val MAE: 0.11195183545351028, Val SSIM: 0.5786694750071769\n","Epoch [12/150], Time: 8.55 seconds\n","Epoch [12/150], Train Loss: 0.03185533632763794, Val Loss: 0.05976691830158234\n","Epoch [12/150], Train MSE: 0.024075815454125404, Train MAE: 0.11524976789951324, Train SSIM: 0.5643566911663931\n","Epoch [12/150], Val MSE: 0.023497937247157097, Val MAE: 0.11354044079780579, Val SSIM: 0.5745141871963566\n","Epoch [13/150], Time: 8.84 seconds\n","Epoch [13/150], Train Loss: 0.03187694246002606, Val Loss: 0.05898526114225387\n","Epoch [13/150], Train MSE: 0.024027256295084953, Train MAE: 0.11525314301252365, Train SSIM: 0.5685191967774919\n","Epoch [13/150], Val MSE: 0.024499235674738884, Val MAE: 0.11669808626174927, Val SSIM: 0.5451080774732967\n","Epoch [14/150], Time: 8.59 seconds\n","Epoch [14/150], Train Loss: 0.03177206471136638, Val Loss: 0.059408911824226376\n","Epoch [14/150], Train MSE: 0.023889830335974693, Train MAE: 0.11463277786970139, Train SSIM: 0.5676565255848045\n","Epoch [14/150], Val MSE: 0.02399466000497341, Val MAE: 0.11465573310852051, Val SSIM: 0.5772374958700388\n","Epoch [15/150], Time: 8.48 seconds\n","Epoch [15/150], Train Loss: 0.03188251661828586, Val Loss: 0.05727716312805812\n","Epoch [15/150], Train MSE: 0.024074053391814232, Train MAE: 0.11538967490196228, Train SSIM: 0.5661942033703454\n","Epoch [15/150], Val MSE: 0.02522617019712925, Val MAE: 0.11895877122879028, Val SSIM: 0.5188324422830072\n","Epoch [16/150], Time: 8.64 seconds\n","Epoch [16/150], Train Loss: 0.03179024780648095, Val Loss: 0.05958739604552587\n","Epoch [16/150], Train MSE: 0.023945903405547142, Train MAE: 0.11487797647714615, Train SSIM: 0.569819842679876\n","Epoch [16/150], Val MSE: 0.02300763688981533, Val MAE: 0.11205241829156876, Val SSIM: 0.5792632217104957\n","Epoch [17/150], Time: 8.67 seconds\n","Epoch [17/150], Train Loss: 0.03178385505931718, Val Loss: 0.05904755687713623\n","Epoch [17/150], Train MSE: 0.023883672431111336, Train MAE: 0.11461392045021057, Train SSIM: 0.5692036390221489\n","Epoch [17/150], Val MSE: 0.023627467453479767, Val MAE: 0.11370813101530075, Val SSIM: 0.5530964866643027\n","Epoch [18/150], Time: 8.70 seconds\n","Epoch [18/150], Train Loss: 0.031605966108185904, Val Loss: 0.062274535497029625\n","Epoch [18/150], Train MSE: 0.023728830739855766, Train MAE: 0.11413039267063141, Train SSIM: 0.5729656304222271\n","Epoch [18/150], Val MSE: 0.02395448461174965, Val MAE: 0.11527349799871445, Val SSIM: 0.5403081496833017\n","Epoch [19/150], Time: 8.47 seconds\n","Epoch [19/150], Train Loss: 0.031735852897167204, Val Loss: 0.060173772811889646\n","Epoch [19/150], Train MSE: 0.023927750065922737, Train MAE: 0.11480860412120819, Train SSIM: 0.5689738098837904\n","Epoch [19/150], Val MSE: 0.023118948563933372, Val MAE: 0.11236293613910675, Val SSIM: 0.5659363226709524\n","Early stopping! No improvement in validation loss.\n","Time: 166.37 seconds\n"]}],"source":["# Instantiate the VAE class\n","network = VanillaVAE(in_channels, latent_dim)\n","\n","max_accuracy = 0\n","min_loss = 1000\n","\n","optimizer = torch.optim.AdamW(network.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=0.001)\n","\n","# Initialize variables for early stopping\n","best_val_loss = float('inf')\n","patience = 0\n","patience_limit = 10  # Number of epochs without improvement before stopping\n","\n","# Check if there is a checkpoint file available\n","start_epoch = 0\n","# if os.path.exists('/content/drive/MyDrive/TU060/Dissertation/Checkpoints/vae_checkpoint_32_16_250_1000.pth'):\n","#     checkpoint = torch.load('/content/drive/MyDrive/TU060/Dissertation/Checkpoints/svae_checkpoint_32_16_250_1000.pth')\n","#     start_epoch = checkpoint['epoch']\n","#     best_val_loss = checkpoint['loss']\n","#     network.load_state_dict(checkpoint['model_state_dict'])\n","#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","#     print(f\"Resuming from epoch {start_epoch + 1}\")\n","\n","# Initialize lists to store training and validation losses\n","train_losses_list = []\n","val_losses_list = []\n","\n","# Initialize lists to store evaluation metrics\n","train_metrics_list = []\n","val_metrics_list = []\n","\n","total_start_time = time.time()\n","\n","# Training loop\n","for epoch in range(start_epoch, epochs):\n","    # Training phase\n","    network.train()\n","    train_loss = 0.0\n","    start_time = time.time()\n","    train_reconstruction = []\n","    train_data = []\n","\n","    for batch_index, data_batch in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        # data_batch = data_batch.to(device)\n","        recons, mu, log_var = network(data_batch)\n","        losses = network.loss_function(recons, data_batch, mu, log_var, 1/len(train_loader))\n","        losses['loss'].backward()\n","        optimizer.step()\n","        train_loss += losses['loss'].item() * data_batch.size(0)\n","\n","        # print(f\"Epoch [{epoch + 1}/{epochs}], Batch [{batch_index}/{len(train_loader)}], Train Loss: {losses['loss'].item():.4f}\")\n","\n","        train_reconstruction.append(recons.detach().numpy())\n","        train_data.append(data_batch.detach().numpy())\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_losses_list.append(train_loss)\n","\n","    # Concatenate training data\n","    train_data = np.concatenate(train_data, axis=0)\n","    train_reconstruction = np.concatenate(train_reconstruction, axis=0)\n","    train_reconstruction = np.squeeze(train_reconstruction)\n","\n","    train_data_flat = train_data.reshape(-1, train_data.shape[2] * train_data.shape[3])  # Flatten to 2D array\n","    train_reconstruction_flat = train_reconstruction.reshape(-1, train_reconstruction.shape[1] * train_reconstruction.shape[2])  # Flatten to 2D array\n","\n","    # Compute training metrics\n","    train_metrics = {\n","        'MSE': mean_squared_error(train_data_flat, train_reconstruction_flat),\n","        'MAE': mean_absolute_error(train_data_flat, train_reconstruction_flat),\n","        'SSIM': ssim(train_data_flat, train_reconstruction_flat, data_range=train_reconstruction_flat.max() - train_reconstruction_flat.min())\n","        # 'MAPE': mean_absolute_percentage_error(train_data_flat, train_reconstruction_flat)\n","    }\n","    train_metrics_list.append(train_metrics)\n","\n","    # Validation phase\n","    network.eval()\n","    val_loss = 0.0\n","    val_reconstruction = []\n","    val_data = []\n","\n","    with torch.no_grad():\n","        for batch_idx, data_batch in enumerate(val_loader):\n","            # data_batch = data_batch.to(device)\n","            recons, mu, log_var = network(data_batch)\n","            val_losses = network.loss_function(recons, data_batch, mu, log_var, 1/len(val_loader))\n","            val_loss += val_losses['loss'].item() * data_batch.size(0)\n","\n","            val_reconstruction.append(recons.detach().numpy())\n","            val_data.append(data_batch.detach().numpy())\n","\n","    val_loss /= len(val_loader.dataset)\n","    val_losses_list.append(val_loss)\n","\n","    end_time = time.time()\n","    epoch_time = end_time - start_time\n","    print(f\"Epoch [{epoch + 1}/{epochs}], Time: {epoch_time:.2f} seconds\")\n","\n","    # print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss}, Val Loss: {val_loss}\")\n","\n","    # Concatenate validation data\n","    val_data = np.concatenate(val_data, axis=0)\n","    val_reconstruction = np.concatenate(val_reconstruction, axis=0)\n","    val_reconstruction = np.squeeze(val_reconstruction)\n","\n","    val_data_flat = val_data.reshape(-1, val_data.shape[2] * val_data.shape[3])  # Flatten to 2D array\n","    val_reconstruction_flat = val_reconstruction.reshape(-1, val_reconstruction.shape[1] * val_reconstruction.shape[2])  # Flatten to 2D array\n","\n","    # Compute validation metrics\n","    val_metrics = {\n","        'MSE': mean_squared_error(val_data_flat, val_reconstruction_flat),\n","        'MAE': mean_absolute_error(val_data_flat, val_reconstruction_flat),\n","        'SSIM': ssim(val_data_flat, val_reconstruction_flat, data_range=val_reconstruction_flat.max() - val_reconstruction_flat.min())\n","        # 'MAPE': mean_absolute_percentage_error(val_data_flat, val_reconstruction_flat)\n","    }\n","    val_metrics_list.append(val_metrics)\n","\n","    # Print training and validation loss for each epoch\n","    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss}, Val Loss: {val_loss}\")\n","    print(f\"Epoch [{epoch+1}/{epochs}], Train MSE: {train_metrics['MSE']}, Train MAE: {train_metrics['MAE']}, Train SSIM: {train_metrics['SSIM']}\")\n","    print(f\"Epoch [{epoch+1}/{epochs}], Val MSE: {val_metrics['MSE']}, Val MAE: {val_metrics['MAE']}, Val SSIM: {val_metrics['SSIM']}\")\n","\n","\n","    # Save model checkpoint after every epoch\n","    # save_checkpoint(epoch, network, optimizer, best_val_loss, f'vae_checkpoint_32_16_25_full_dim25_{epoch}.pth')\n","\n","    # Check for improvement in validation loss\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        patience = 0\n","        # Save the model to the specified folder\n","        # model_path = os.path.join(save_folder, 'best_model.pth')\n","        # torch.save(network.state_dict(), model_path)\n","    else:\n","        patience += 1\n","\n","    # Early stopping\n","    if patience > patience_limit:\n","        print(\"Early stopping! No improvement in validation loss.\")\n","        break\n","\n","# Calculate time\n","total_end_time = time.time()\n","epoch_time = total_end_time - total_start_time\n","print(f\"Time: {epoch_time:.2f} seconds\")\n","\n","# # Save losses as CSV\n","# losses_df = pd.DataFrame({\n","#     'Epoch': range(start_epoch, epoch +1),\n","#     'Train Loss': train_losses_list,\n","#     'Validation Loss': val_losses_list\n","# })\n","# losses_df.to_csv('vae2_training_losses_full.csv', index=False)\n","\n","# Save losses as CSV\n","# csv_path = os.path.join(save_folder, 'vae3_30_full.csv')\n","# losses_df = pd.DataFrame({\n","#     'Epoch': range(start_epoch, epoch +1),\n","#     'Train Loss': train_losses_list,\n","#     'Validation Loss': val_losses_list,\n","#     'Train MSE': [metrics['MSE'] for metrics in train_metrics_list],\n","#     'Train MAE': [metrics['MAE'] for metrics in train_metrics_list],\n","#     'Train SSIM': [metrics['SSIM'] for metrics in train_metrics_list],\n","#     # 'Train MAPE': [metrics['MAPE'] for metrics in train_metrics_list],\n","#     'Validation MSE': [metrics['MSE'] for metrics in val_metrics_list],\n","#     'Validation MAE': [metrics['MAE'] for metrics in val_metrics_list],\n","#     'Validation SSIM': [metrics['SSIM'] for metrics in val_metrics_list],\n","#     # 'Validation MAPE': [metrics['MAPE'] for metrics in val_metrics_list]\n","# })\n","# losses_df.to_csv(csv_path, index=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"IrXjn6SG82pH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718559481290,"user_tz":-60,"elapsed":944,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"}},"outputId":"2fea8bbb-6da1-4d40-aea8-927687a5c986"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 0.038744326680898666\n","Mean Absolute Error: 0.1544773429632187\n","SSIM: 0.0006281379864081619\n"]}],"source":["# Load the model\n","# network = VanillaVAE(in_channels, latent_dim)\n","# checkpoint = torch.load(model_path)\n","# network.load_state_dict(checkpoint)\n","# network.eval()\n","\n","# Evaluation\n","reconstruction = []\n","data_test = []\n","\n","network.eval()\n","with torch.no_grad():\n","    for batch_idx, data_batch in enumerate(test_loader):\n","        # data_batch = data_batch.to(device)\n","        recons, mu, log_var = network(data_batch)\n","        reconstruction.append(recons.numpy())\n","        data_test.append(data_batch.numpy())\n","\n","# # Save data_test\n","# data_test = []\n","# with torch.no_grad():\n","#     for batch_idx, data_batch in enumerate(test_loader):\n","#         # real_img = real_img.to(device)\n","#         data_test.append(data_batch.numpy())\n","data_test = np.concatenate(data_test, axis=0)\n","\n","# Calculate evaluation metrics\n","reconstruction = np.concatenate(reconstruction, axis=0)\n","reconstruction = np.squeeze(reconstruction)\n","\n","data_test_flat = data_test.reshape(-1, data_test.shape[2] * data_test.shape[3])  # Flatten to 2D array\n","reconstruction_flat = reconstruction.reshape(-1, reconstruction.shape[1] * reconstruction.shape[2])  # Flatten to 2D array\n","\n","mse = mean_squared_error(data_test_flat, reconstruction_flat)\n","mae = mean_absolute_error(data_test_flat, reconstruction_flat)\n","ssim_score = ssim(data_test_flat, reconstruction_flat,\n","                  data_range=reconstruction_flat.max() - reconstruction_flat.min())\n","# mape = mean_absolute_percentage_error(data_test_flat, reconstruction_flat)\n","\n","print(f\"Mean Squared Error: {mse}\")\n","print(f\"Mean Absolute Error: {mae}\")\n","print(f\"SSIM: {ssim_score}\")\n","# print(f\"Mean Absolute Percentage Error: {mape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DD95ifiWthqb","executionInfo":{"status":"aborted","timestamp":1718559449818,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ayano Yamamoto","userId":"07664729366976661766"}}},"outputs":[],"source":["# Visualize actual and predicted images with sample indices\n","n_samples = 5  # Number of samples to visualize\n","\n","# Select random samples\n","available_indices = list(range(len(data_test)))\n","indices = np.random.choice(available_indices, size=n_samples, replace=False)\n","\n","# Plot actual and predicted images\n","fig, axes = plt.subplots(nrows=2, ncols=n_samples, figsize=(15, 5))\n","\n","for i, idx in enumerate(indices):\n","    # Remove selected index from available indices\n","    available_indices.remove(idx)\n","\n","    # Plot actual image with index\n","    axes[0, i].imshow(data_test[idx].squeeze(), cmap='jet')\n","    axes[0, i].set_title(f\"Actual ({idx})\")\n","    axes[0, i].axis('off')\n","\n","    # Plot predicted image with index\n","    reconstructed_img = reconstruction[idx]\n","    axes[1, i].imshow(reconstructed_img, cmap='jet')\n","    axes[1, i].set_title(f\"Predicted ({idx})\")\n","    axes[1, i].axis('off')\n","\n","plt.tight_layout()\n","# img_path = os.path.join(save_folder, 'vae3_30_full_2.png')\n","# plt.savefig(img_path)\n","plt.show()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":["_3-ElNQxTXzx"],"authorship_tag":"ABX9TyNe+yZmlh7x2cdtVZlyV390"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}