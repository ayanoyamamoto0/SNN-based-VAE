{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up"
      ],
      "metadata": {
        "id": "37HImWxZ8vUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV86I9iyIHX"
      },
      "outputs": [],
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-alScVnKPlQy"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import os\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create save folder if it doesn't exist\n",
        "save_folder = 'location_to_save'\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)"
      ],
      "metadata": {
        "id": "2QRjC9DK9LiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Hyperparameters"
      ],
      "metadata": {
        "id": "VpVNcTUQ89Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "epochs = 150\n",
        "batch_size = 32\n",
        "in_channels = 1\n",
        "lr = 0.001\n",
        "latent_dim = 35\n",
        "input_size = 40\n",
        "k = 20"
      ],
      "metadata": {
        "id": "IVAXvIC-9AOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "p3m6rAi8_sCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and normalise data\n",
        "raw = np.load('location_of_npy_file')\n",
        "data_norm = np.zeros_like(raw)\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    min_val = raw[i].min()\n",
        "    max_val = raw[i].max()\n",
        "    data_norm[i] = (raw[i] - min_val) / (max_val - min_val)\n",
        "\n",
        "data_norm_reshape = data_norm.reshape(-1, 1, raw.shape[1], raw.shape[2]).astype(np.float32)\n",
        "\n",
        "# Split data\n",
        "data_train, data_test = train_test_split(data_norm_reshape, test_size=0.3, random_state=42, shuffle=True)\n",
        "data_test, data_val = train_test_split(data_test, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "NxoC8gEc_zOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3-ElNQxTXzx"
      },
      "source": [
        "# ANN-based VAE Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVN6iTlFP3Nc"
      },
      "outputs": [],
      "source": [
        "class VanillaVAE(nn.Module):\n",
        "    def __init__(self, in_channels, latent_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        modules = []\n",
        "        hidden_dims = [32, 64, 128]\n",
        "        self.hidden_dims = hidden_dims.copy()\n",
        "\n",
        "        # Build Encoder\n",
        "        for h_dim in hidden_dims:\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels, out_channels=h_dim, kernel_size=3, stride=2, padding=1),\n",
        "                    nn.BatchNorm2d(h_dim),\n",
        "                    nn.LeakyReLU())\n",
        "            )\n",
        "            in_channels = h_dim\n",
        "\n",
        "        self.encoder = nn.Sequential(*modules)\n",
        "        self.fc_mu = nn.Linear(hidden_dims[-1]*25, latent_dim)\n",
        "        self.fc_var = nn.Linear(hidden_dims[-1]*25, latent_dim)\n",
        "\n",
        "        # Build Decoder\n",
        "        modules = []\n",
        "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 25)\n",
        "        hidden_dims.reverse()\n",
        "\n",
        "        for i in range(len(hidden_dims) - 1):\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.ConvTranspose2d(hidden_dims[i], hidden_dims[i + 1], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
        "                    nn.LeakyReLU())\n",
        "            )\n",
        "\n",
        "        self.decoder = nn.Sequential(*modules)\n",
        "\n",
        "        self.final_layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(hidden_dims[-1], hidden_dims[-1], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(hidden_dims[-1]),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(hidden_dims[-1], out_channels=self.in_channels, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, input):\n",
        "        result = self.encoder(input)\n",
        "        result = torch.flatten(result, start_dim=1)\n",
        "        mu = self.fc_mu(result)\n",
        "        log_var = self.fc_var(result)\n",
        "        return [mu, log_var]\n",
        "\n",
        "    def decode(self, z):\n",
        "        result = self.decoder_input(z)\n",
        "        result = result.view(-1, self.hidden_dims[-1], 5, 5)\n",
        "        result = self.decoder(result)\n",
        "        result = self.final_layer(result)\n",
        "        return result\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, input):\n",
        "        mu, log_var = self.encode(input)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return self.decode(z), mu, log_var\n",
        "\n",
        "    def loss_function(self, recons_img, input_img, mu, log_var, kld_weight) -> dict:\n",
        "        recons_loss = F.mse_loss(recons_img, input_img)\n",
        "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)\n",
        "        loss = recons_loss + kld_weight * kld_loss\n",
        "        return {'loss': loss, 'Reconstruction_Loss': recons_loss, 'KLD': kld_loss}\n",
        "\n",
        "    def sample(self, num_samples: int, current_device: int, **kwargs):\n",
        "        z = torch.randn(num_samples, self.latent_dim)\n",
        "        z = z.to(current_device)\n",
        "        samples = self.decode(z)\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation"
      ],
      "metadata": {
        "id": "Y4sjncG-BfCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the VAE class\n",
        "network = VanillaVAE(in_channels, latent_dim)\n",
        "optimizer = torch.optim.AdamW(network.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "# Initialise variables for early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 0\n",
        "patience_limit = 10\n",
        "\n",
        "# Initialise lists to store training and validation losses\n",
        "train_losses_list = []\n",
        "val_losses_list = []\n",
        "\n",
        "# Initialise lists to store evaluation metrics\n",
        "train_metrics_list = []\n",
        "val_metrics_list = []\n",
        "\n",
        "total_start_time = time.time()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    # Training phase\n",
        "    network.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    train_reconstruction = []\n",
        "    train_data = []\n",
        "\n",
        "    for data_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        recons, mu, log_var = network(data_batch)\n",
        "        losses = network.loss_function(recons, data_batch, mu, log_var, 1/len(train_loader))\n",
        "        losses['loss'].backward()\n",
        "        optimizer.step()\n",
        "        train_loss += losses['loss'].item() * data_batch.size(0)\n",
        "        train_reconstruction.append(recons.detach().numpy())\n",
        "        train_data.append(data_batch.detach().numpy())\n",
        "\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_losses_list.append(train_loss)\n",
        "    train_data = np.concatenate(train_data, axis=0)\n",
        "    train_reconstruction = np.concatenate(train_reconstruction, axis=0)\n",
        "    train_reconstruction = np.squeeze(train_reconstruction)\n",
        "\n",
        "    train_data_flat = train_data.reshape(-1, train_data.shape[2] * train_data.shape[3])\n",
        "    train_reconstruction_flat = train_reconstruction.reshape(-1, train_reconstruction.shape[1] * train_reconstruction.shape[2])\n",
        "\n",
        "    train_metrics = {\n",
        "        'MSE': mean_squared_error(train_data_flat, train_reconstruction_flat),\n",
        "        'MAE': mean_absolute_error(train_data_flat, train_reconstruction_flat),\n",
        "        'SSIM': ssim(train_data_flat, train_reconstruction_flat, data_range=train_reconstruction_flat.max() - train_reconstruction_flat.min())\n",
        "    }\n",
        "    train_metrics_list.append(train_metrics)\n",
        "\n",
        "    # Validation phase\n",
        "    network.eval()\n",
        "    val_loss = 0.0\n",
        "    val_reconstruction = []\n",
        "    val_data = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data_batch in val_loader:\n",
        "            recons, mu, log_var = network(data_batch)\n",
        "            val_losses = network.loss_function(recons, data_batch, mu, log_var, 1/len(val_loader))\n",
        "            val_loss += val_losses['loss'].item() * data_batch.size(0)\n",
        "            val_reconstruction.append(recons.detach().numpy())\n",
        "            val_data.append(data_batch.detach().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_losses_list.append(val_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Time: {epoch_time:.2f} seconds\")\n",
        "    val_data = np.concatenate(val_data, axis=0)\n",
        "    val_reconstruction = np.concatenate(val_reconstruction, axis=0)\n",
        "    val_reconstruction = np.squeeze(val_reconstruction)\n",
        "\n",
        "    val_data_flat = val_data.reshape(-1, val_data.shape[2] * val_data.shape[3])\n",
        "    val_reconstruction_flat = val_reconstruction.reshape(-1, val_reconstruction.shape[1] * val_reconstruction.shape[2])\n",
        "\n",
        "    val_metrics = {\n",
        "        'MSE': mean_squared_error(val_data_flat, val_reconstruction_flat),\n",
        "        'MAE': mean_absolute_error(val_data_flat, val_reconstruction_flat),\n",
        "        'SSIM': ssim(val_data_flat, val_reconstruction_flat, data_range=val_reconstruction_flat.max() - val_reconstruction_flat.min())\n",
        "    }\n",
        "    val_metrics_list.append(val_metrics)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Train MSE: {train_metrics['MSE']}, Train MAE: {train_metrics['MAE']}, Train SSIM: {train_metrics['SSIM']}\")\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Val MSE: {val_metrics['MSE']}, Val MAE: {val_metrics['MAE']}, Val SSIM: {val_metrics['SSIM']}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(network.state_dict(), os.path.join(save_folder, 'best_model.pth'))\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "\n",
        "    if patience >= patience_limit:\n",
        "        print(\"Early stopping due to no improvement in validation loss.\")\n",
        "        break\n",
        "\n",
        "total_end_time = time.time()\n",
        "total_training_time = total_end_time - total_start_time\n",
        "print(f\"Total training time: {total_training_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "TH5AIG0xBl-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "YwY3RTTEIHnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrXjn6SG82pH"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "reconstruction = []\n",
        "data_test = []\n",
        "\n",
        "network.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_idx, data_batch in enumerate(test_loader):\n",
        "        # data_batch = data_batch.to(device)\n",
        "        recons, mu, log_var = network(data_batch)\n",
        "        reconstruction.append(recons.numpy())\n",
        "        data_test.append(data_batch.numpy())\n",
        "\n",
        "data_test = np.concatenate(data_test, axis=0)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "reconstruction = np.concatenate(reconstruction, axis=0)\n",
        "reconstruction = np.squeeze(reconstruction)\n",
        "\n",
        "data_test_flat = data_test.reshape(-1, data_test.shape[2] * data_test.shape[3])  # Flatten to 2D array\n",
        "reconstruction_flat = reconstruction.reshape(-1, reconstruction.shape[1] * reconstruction.shape[2])  # Flatten to 2D array\n",
        "\n",
        "mse = mean_squared_error(data_test_flat, reconstruction_flat)\n",
        "mae = mean_absolute_error(data_test_flat, reconstruction_flat)\n",
        "ssim_score = ssim(data_test_flat, reconstruction_flat,\n",
        "                  data_range=reconstruction_flat.max() - reconstruction_flat.min())\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"SSIM: {ssim_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisation"
      ],
      "metadata": {
        "id": "9bx0PWDiIor3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD95ifiWthqb"
      },
      "outputs": [],
      "source": [
        "# Visualise actual and predicted images with sample indices\n",
        "n_samples = 5\n",
        "\n",
        "# Select random samples\n",
        "available_indices = list(range(len(data_test)))\n",
        "indices = np.random.choice(available_indices, size=n_samples, replace=False)\n",
        "\n",
        "# Plot actual and predicted images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=n_samples, figsize=(15, 5))\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    # Remove selected index from available indices\n",
        "    available_indices.remove(idx)\n",
        "\n",
        "    # Plot actual image with index\n",
        "    axes[0, i].imshow(data_test[idx].squeeze(), cmap='jet')\n",
        "    axes[0, i].set_title(f\"Actual ({idx})\")\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    # Plot predicted image with index\n",
        "    reconstructed_img = reconstruction[idx]\n",
        "    axes[1, i].imshow(reconstructed_img, cmap='jet')\n",
        "    axes[1, i].set_title(f\"Predicted ({idx})\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "_3-ElNQxTXzx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}